/*!
 * Copyright 2016 The ANTLR Project. All rights reserved.
 * Licensed under the BSD-3-Clause license. See LICENSE file in the project root for license information.
 */

// ConvertTo-TS run at 2016-10-04T11:27:04.9040731-07:00

// import org.junit.Test;

// import static org.junit.Assert.*;

/**
 * Lexer rules are little quirky when it comes to wildcards. Problem
 * stems from the fact that we want the longest match to win among
 * several rules and even within a rule. However, that conflicts
 * with the notion of non-greedy, which by definition tries to match
 * the fewest possible. During ATN construction, non-greedy loops
 * have their entry and exit branches reversed so that the ATN
 * simulator will see the exit branch 1st, giving it a priority. The
 * 1st path to the stop state kills any other paths for that rule
 * that begin with the wildcard. In general, this does everything we
 * want, but occasionally there are some quirks as you'll see from
 * the tests below.
 */
export class TestATNLexerInterpreter extends BaseTest {
	@Test testLexerTwoRules(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'a' ;\n" +
			"B : 'b' ;\n");
		let expecting: string =  "A, B, A, B, EOF";
		checkLexerMatches(lg, "abab", expecting);
	}

	@Test testShortLongRule(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xy'\n" +
			"  | 'xyz'\n" + // this alt is preferred since there are no non-greedy configs
			"  ;\n" +
			"Z : 'z'\n" +
			"  ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyz", "A, EOF");
	}

	@Test testShortLongRule2(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xyz'\n" +  // make sure nongreedy mech cut off doesn't kill this alt
			"  | 'xy'\n" +
			"  ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyz", "A, EOF");
	}

	@Test testWildOnEndFirstAlt(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xy' .\n" + // should pursue '.' since xyz hits stop first, before 2nd alt
			"  | 'xy'\n" +
			"  ;\n" +
			"Z : 'z'\n" +
			"  ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyz", "A, EOF");
	}

	@Test testWildOnEndLastAlt(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xy'\n" +
			"  | 'xy' .\n" +  // this alt is preferred since there are no non-greedy configs
			"  ;\n" +
			"Z : 'z'\n" +
			"  ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyz", "A, EOF");
	}

	@Test testWildcardNonQuirkWhenSplitBetweenTwoRules(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'xy' ;\n" +
			"B : 'xy' . 'z' ;\n");
		checkLexerMatches(lg, "xy", "A, EOF");
		checkLexerMatches(lg, "xyqz", "B, EOF");
	}

	@Test testLexerLoops(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"INT : '0'..'9'+ ;\n" +
			"ID : 'a'..'z'+ ;\n");
		let expecting: string =  "ID, INT, ID, INT, EOF";
		checkLexerMatches(lg, "a34bde3", expecting);
	}

	@Test testLexerNotSet(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('a'|'b')\n ;");
		let expecting: string =  "ID, EOF";
		checkLexerMatches(lg, "c", expecting);
	}

	@Test testLexerSetUnicodeBMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ('\u611B'|'\u611C')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, "\u611B", expecting);
	}

	@Test testLexerNotSetUnicodeBMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('\u611B'|'\u611C')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, "\u611D", expecting);
	}

		@Test testLexerNotSetUnicodeBMPMatchesSMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('\u611B'|'\u611C')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, new StringBuilder().appendCodePoint(0x1F4A9).toString(), expecting);
	}

	@Test testLexerSetUnicodeSMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ('\\u{1F4A9}'|'\\u{1F4AA}')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, new StringBuilder().appendCodePoint(0x1F4A9).toString(), expecting);
	}

	@Test testLexerNotBMPSetMatchesUnicodeSMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('a'|'b')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, new StringBuilder().appendCodePoint(0x1F4A9).toString(), expecting);
	}

	@Test testLexerNotBMPSetMatchesBMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('a'|'b')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, "\u611B", expecting);
	}

	@Test testLexerNotBMPSetMatchesSMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('a'|'b')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, new StringBuilder().appendCodePoint(0x1F4A9).toString(), expecting);
	}

	@Test testLexerNotSMPSetMatchesBMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('\\u{1F4A9}'|'\\u{1F4AA}')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, "\u611B", expecting);
	}

	@Test testLexerNotSMPSetMatchesSMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ~('\\u{1F4A9}'|'\\u{1F4AA}')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, new StringBuilder().appendCodePoint(0x1D7C0).toString(), expecting);
	}

	@Test testLexerRangeUnicodeSMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ('\\u{1F4A9}'..'\\u{1F4B0}')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, new StringBuilder().appendCodePoint(0x1F4AF).toString(), expecting);
	}

	@Test testLexerRangeUnicodeBMPToSMP(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"ID : ('\\u611B'..'\\u{1F4B0}')\n ;");
		let expecting: string = "ID, EOF";
		checkLexerMatches(lg, new StringBuilder().appendCodePoint(0x12001).toString(), expecting);
	}

	@Test testLexerKeywordIDAmbiguity(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"KEND : 'end' ;\n" +
			"ID : 'a'..'z'+ ;\n" +
			"WS : (' '|'\\n')+ ;");
		let expecting: string =  "ID, EOF";
		//checkLexerMatches(lg, "e", expecting);
		expecting = "KEND, EOF";
		checkLexerMatches(lg, "end", expecting);
		expecting = "ID, EOF";
		checkLexerMatches(lg, "ending", expecting);
		expecting = "ID, WS, KEND, WS, ID, EOF";
		checkLexerMatches(lg, "a end bcd", expecting);
	}

	@Test testLexerRuleRef(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"INT : DIGIT+ ;\n" +
			"fragment DIGIT : '0'..'9' ;\n" +
			"WS : (' '|'\\n')+ ;");
		let expecting: string =  "INT, WS, INT, EOF";
		checkLexerMatches(lg, "32 99", expecting);
	}

	@Test testRecursiveLexerRuleRef(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '/*' (CMT | ~'*')+ '*/' ;\n" +
			"WS : (' '|'\\n')+ ;");
		let expecting: string =  "CMT, WS, CMT, EOF";
		checkLexerMatches(lg, "/* ick */\n/* /*nested*/ */", expecting);
	}

	@Test testRecursiveLexerRuleRefWithWildcard(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '/*' (CMT | .)*? '*/' ;\n" +
			"WS : (' '|'\\n')+ ;");

		let expecting: string =  "CMT, WS, CMT, WS, EOF";
		checkLexerMatches(lg,
						  "/* ick */\n" +
						  "/* /* */\n" +
						  "/* /*nested*/ */\n",
						  expecting);
	}

	@Test testLexerWildcardGreedyLoopByDefault(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .* '\\n' ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//x\n//y\n", expecting);
	}

	@Test testLexerWildcardLoopExplicitNonGreedy(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .*? '\\n' ;\n");
		let expecting: string =  "CMT, CMT, EOF";
		checkLexerMatches(lg, "//x\n//y\n", expecting);
	}

	@Test testLexerEscapeInString(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"STR : '[' ('~' ']' | .)* ']' ;\n");
		checkLexerMatches(lg, "[a~]b]", "STR, EOF");
		checkLexerMatches(lg, "[a]", "STR, EOF");
	}

	@Test testLexerWildcardGreedyPlusLoopByDefault(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .+ '\\n' ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//x\n//y\n", expecting);
	}

	@Test testLexerWildcardExplicitNonGreedyPlusLoop(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .+? '\\n' ;\n");
		let expecting: string =  "CMT, CMT, EOF";
		checkLexerMatches(lg, "//x\n//y\n", expecting);
	}

	// does not fail since ('*/')? can't match and have rule succeed
	@Test testLexerGreedyOptionalShouldWorkAsWeExpect(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '/*' ('*/')? '*/' ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "/**/", expecting);
	}

	@Test testGreedyBetweenRules(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : '<a>' ;\n" +
			"B : '<' .+ '>' ;\n");
		let expecting: string =  "B, EOF";
		checkLexerMatches(lg, "<a><x>", expecting);
	}

	@Test testNonGreedyBetweenRules(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : '<a>' ;\n" +
			"B : '<' .+? '>' ;\n");
		let expecting: string =  "A, B, EOF";
		checkLexerMatches(lg, "<a><x>", expecting);
	}

	@Test testEOFAtEndOfLineComment(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' ~('\\n')* ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//x", expecting);
	}

	@Test testEOFAtEndOfLineComment2(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' ~('\\n'|'\\r')* ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//x", expecting);
	}

	/** only positive sets like (EOF|'\n') can match EOF and not in wildcard or ~foo sets
	 *  EOF matches but does not advance cursor.
	 */
	@Test testEOFInSetAtEndOfLineComment(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"CMT : '//' .* (EOF|'\\n') ;\n");
		let expecting: string =  "CMT, EOF";
		checkLexerMatches(lg, "//", expecting);
	}

	@Test testEOFSuffixInSecondRule(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'a' ;\n"+ // shorter than 'a' EOF, despite EOF being 0 width
			"B : 'a' EOF ;\n");
		let expecting: string =  "B, EOF";
		checkLexerMatches(lg, "a", expecting);
	}

	@Test testEOFSuffixInFirstRule(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"A : 'a' EOF ;\n"+
			"B : 'a';\n");
		let expecting: string =  "A, EOF";
		checkLexerMatches(lg, "a", expecting);
	}

	@Test testEOFByItself(): void {
		let lg: LexerGrammar =  new LexerGrammar(
			"lexer grammar L;\n"+
			"DONE : EOF ;\n"+
			"A : 'a';\n");
		let expecting: string =  "A, DONE, EOF";
		checkLexerMatches(lg, "a", expecting);
	}

	protected checkLexerMatches(lg: LexerGrammar, inputString: string, expecting: string): void {
		let atn: ATN =  createATN(lg, true);
		let input: CharStream =  new ANTLRInputStream(inputString);
		let startState: ATNState =  atn.modeNameToStartState.get("DEFAULT_MODE");
		let dot: DOTGenerator =  new DOTGenerator(lg);
		console.log(dot.getDOT(startState, true));

		let tokenTypes: List<string> =  getTokenTypes(lg, atn, input);

		let result: string =  Utils.join(tokenTypes.iterator(), ", ");
		console.log(tokenTypes);
		assertEquals(expecting, result);
	}

}
